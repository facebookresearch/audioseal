{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Benchmarking Audioseal on the SHUSH attack applied on RAVDESS Dataset\n","\n","In this notebook, we outline the steps taken to benchmark the Audioseal architecture against different attacks on a dataset of audio files.  \n","In particular, we follow these steps:\n","- Load audio files from a dataset \n","- Watermark each audio file using Audioseal\n","- Perform perturbations/attacks to the audio files\n","- Detect the watermarks on these attacked files and keep track of the confidence of Audioseal in its predictions that the files are watermarked.\n","\n","\n","For a better understanding of Audioseal and its functionalities, it is highly recommended to go through the [Getting started notebook](https://github.com/facebookresearch/audioseal/blob/main/examples/Getting_started.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset\n","\n","We use the [RAVDESS Emotional Speech audio](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) dataset for this experiment.   \n","This notebook provide two options to download and load the dataset either `manually` or `automatically` within the notebook."]},{"cell_type":"markdown","metadata":{},"source":["### 1. Manual Dataset Download\n","To download the dataset manually, follow these steps:\n","\n","- Visit Kaggle's [RAVDESS Emotional Speech audio](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)o dataset page.\n","- Download the dataset to your local machine and place the unzipped files in the ./kaggle folder.\n","- Skip `Auto Download Step 1 & 2`"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Automatic Dataset Download in Notebook\n","For automated download: Run `Auto Download Step 1 & 2`\n","\n","- Obtain your Kaggle API credentials by navigating to `Account Settings` on Kaggle and generating a `kaggle.json` file.\n","- Place the `kaggle.json` file in the `./kaggle` folder at the same location as this notebook.\n","- The code will handle moving the `kaggle.json` file to the appropriate location and `download/unzip` the dataset into the `./kaggle` folder automatically."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: kaggle in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (1.6.17)\n","Requirement already satisfied: six>=1.10 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (2024.8.30)\n","Requirement already satisfied: python-dateutil in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: requests in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (2.32.3)\n","Requirement already satisfied: tqdm in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (4.66.5)\n","Requirement already satisfied: python-slugify in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: urllib3 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (2.2.3)\n","Requirement already satisfied: bleach in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from kaggle) (6.1.0)\n","Requirement already satisfied: webencodings in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from requests->kaggle) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /home/hastagab/Desktop/MLH/audioseal/evn/lib/python3.12/site-packages (from requests->kaggle) (3.10)\n"]}],"source":["# Auto Download Step 1\n","\n","import os\n","import shutil\n","!pip install kaggle\n","\n","if not os.path.exists('./kaggle'):\n","    os.makedirs('./kaggle')\n","\n","if not os.path.exists(os.path.expanduser('~/.kaggle')):\n","    os.makedirs(os.path.expanduser('~/.kaggle'))\n","\n","shutil.copy('./kaggle/kaggle.json', os.path.expanduser('~/.kaggle/kaggle.json'))\n","os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n","Dataset downloaded and extracted successfully to ./kaggle folder!\n"]}],"source":["# Auto Download Step 2\n","\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","if not os.path.exists('./kaggle'):\n","    os.makedirs('./kaggle')\n","\n","api = KaggleApi()\n","api.authenticate()\n","\n","api.dataset_download_files('uwrfkaggler/ravdess-emotional-speech-audio', path='./kaggle', unzip=True)\n","\n","print(\"Dataset downloaded and extracted successfully to ./kaggle folder!\")"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-15T06:51:03.909949Z","iopub.status.busy":"2024-03-15T06:51:03.909220Z","iopub.status.idle":"2024-03-15T06:51:04.354260Z","shell.execute_reply":"2024-03-15T06:51:04.353256Z","shell.execute_reply.started":"2024-03-15T06:51:03.909904Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of input files: 2880\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","all_input_files = []\n","PARENT_FILES_DIR = './kaggle'\n","\n","# Load .wav audio files from the dataset in ./kaggle folder\n","for dirname, _, filenames in os.walk(PARENT_FILES_DIR):\n","    for filename in filenames:\n","        if filename.endswith(\".wav\"):\n","            all_input_files.append(os.path.join(dirname, filename))\n","\n","print(f\"Number of input files: {len(all_input_files)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Installations and Imports "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:05.910354Z","iopub.status.busy":"2024-03-15T06:51:05.909237Z","iopub.status.idle":"2024-03-15T06:51:20.351281Z","shell.execute_reply":"2024-03-15T06:51:20.350239Z","shell.execute_reply.started":"2024-03-15T06:51:05.910319Z"},"trusted":true},"outputs":[],"source":["import sys\n","!{sys.executable} -m pip install -q torchaudio soundfile matplotlib audioseal\n","\n","import typing as tp\n","import julius\n","import torch\n","import torchaudio\n","import urllib"]},{"cell_type":"markdown","metadata":{},"source":["### Load Audioseal models"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.354221Z","iopub.status.busy":"2024-03-15T06:51:20.353436Z","iopub.status.idle":"2024-03-15T06:51:20.378701Z","shell.execute_reply":"2024-03-15T06:51:20.377805Z","shell.execute_reply.started":"2024-03-15T06:51:20.354185Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.380975Z","iopub.status.busy":"2024-03-15T06:51:20.379901Z","iopub.status.idle":"2024-03-15T06:51:20.919397Z","shell.execute_reply":"2024-03-15T06:51:20.918564Z","shell.execute_reply.started":"2024-03-15T06:51:20.380948Z"},"trusted":true},"outputs":[],"source":["from audioseal import AudioSeal\n","\n","model = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n","detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")"]},{"cell_type":"markdown","metadata":{},"source":["### Helper functions to load audio data, watermark audio, and get prediction scores for audio"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.922026Z","iopub.status.busy":"2024-03-15T06:51:20.921593Z","iopub.status.idle":"2024-03-15T06:51:21.091167Z","shell.execute_reply":"2024-03-15T06:51:21.090157Z","shell.execute_reply.started":"2024-03-15T06:51:20.921992Z"},"trusted":true},"outputs":[],"source":["model = model.to(device)\n","detector = detector.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:21.092660Z","iopub.status.busy":"2024-03-15T06:51:21.092352Z","iopub.status.idle":"2024-03-15T06:51:21.105098Z","shell.execute_reply":"2024-03-15T06:51:21.104097Z","shell.execute_reply.started":"2024-03-15T06:51:21.092635Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Secret message: tensor([[1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1]], dtype=torch.int32)\n"]}],"source":["secret_message = torch.randint(0, 2, (1, 16), dtype=torch.int32)\n","secret_message = secret_message.to(device)\n","print(f\"Secret message: {secret_message}\")\n","\n","# Function to load an audio file from its file path\n","def load_audio_file(\n","    file_path: str\n",") -> tp.Optional[tp.Tuple[torch.Tensor, int]]:\n","    try:\n","        wav, sample_rate = torchaudio.load(file_path)\n","        return wav, sample_rate\n","    except Exception as e:\n","        print(f\"Error while loading audio: {e}\")\n","        return None\n","    \n","# Function to generate a watermark for the audio and embed it into a new audio tensor\n","def generate_watermark_audio(\n","    tensor: torch.Tensor,\n","    sample_rate: int\n",") -> tp.Optional[torch.Tensor]:\n","    try:\n","        global model, device, secret_message\n","        audios = tensor.unsqueeze(0).to(device)\n","        watermarked_audio = model(audios, sample_rate=sample_rate, message=secret_message.to(device), alpha=1)\n","        return watermarked_audio\n","\n","    \n","    except Exception as e:\n","        print(f\"Error while watermarking audio: {e}\")\n","        return None\n","    \n","# Function to get the confidence score that an audio tensor was watermarked by Audioseal\n","def detect_watermark_audio(\n","    tensor: torch.Tensor,\n","    sample_rate: int,\n","    message_threshold: float = 0.50\n",") -> tp.Optional[float]:\n","    try:\n","        global detector, device\n","        # In our analysis we are not concerned with the hidden/embedded message as of now\n","        result, _ = detector.detect_watermark(tensor, sample_rate=sample_rate, message_threshold=message_threshold)\n","        return float(result)\n","    except Exception as e:\n","        print(f\"Error while detecting watermark: {e}\")\n","        return None"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Audio attacks\n","\n","- In this notebook, we use the `SHUSH` attack.\n","- For more attacks and their descriptions, please refer to the [source](https://github.com/facebookresearch/audioseal/blob/main/examples/attacks.py).\n","- To run this notebook on cloud ENVs (Colab/Kaggle), copy [attaks.py](https://github.com/facebookresearch/audioseal/blob/main/examples/attacks.py) to your root folder as this notebook."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:33.919489Z","iopub.status.busy":"2024-03-15T06:51:33.919084Z","iopub.status.idle":"2024-03-15T06:51:33.962401Z","shell.execute_reply":"2024-03-15T06:51:33.961261Z","shell.execute_reply.started":"2024-03-15T06:51:33.919460Z"},"trusted":true},"outputs":[],"source":["from attacks import AudioEffects as af"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Experimental setup\n","- `fraction` values: \\{0.1\\%, 1\\%, 10\\%, 30\\%\\}\n","- `nomenclature` : n, s, m, l\n","\n","In this notebook, we set the above parameters for the SHUSH attack and note the average confidence scores of Audioseal in predicting the presence of watermarks for these attacked audio files."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:39.665411Z","iopub.status.busy":"2024-03-15T06:51:39.665025Z","iopub.status.idle":"2024-03-15T06:51:39.673355Z","shell.execute_reply":"2024-03-15T06:51:39.672473Z","shell.execute_reply.started":"2024-03-15T06:51:39.665382Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x754dff9ad0d0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import random\n","random.seed(42)\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(42)\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:40.533674Z","iopub.status.busy":"2024-03-15T06:51:40.532744Z","iopub.status.idle":"2024-03-15T06:59:10.240026Z","shell.execute_reply":"2024-03-15T06:59:10.239069Z","shell.execute_reply.started":"2024-03-15T06:51:40.533640Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2880 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["  9%|▊         | 249/2880 [05:38<40:45,  1.08it/s]  "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 52324] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/Actor_01/03-01-08-01-02-02-01.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 271/2880 [06:02<44:22,  1.02s/it]  "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 57663] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/Actor_01/03-01-02-01-01-02-01.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▎        | 389/2880 [08:01<45:48,  1.10s/it]  "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 69942] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/Actor_20/03-01-06-01-01-02-20.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 406/2880 [08:16<39:30,  1.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 55528] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/Actor_20/03-01-03-01-02-01-20.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 1029/2880 [19:04<28:56,  1.07it/s] "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 52324] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/audio_speech_actors_01-24/Actor_01/03-01-08-01-02-02-01.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▋      | 1051/2880 [19:26<30:44,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 57663] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/audio_speech_actors_01-24/Actor_01/03-01-02-01-01-02-01.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1169/2880 [21:20<29:49,  1.05s/it]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 69942] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/audio_speech_actors_01-24/Actor_20/03-01-06-01-01-02-20.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 1186/2880 [21:36<27:26,  1.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 55528] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/audio_speech_actors_01-24/Actor_20/03-01-03-01-02-01-20.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 1697/2880 [29:41<15:43,  1.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 67807] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/audio_speech_actors_01-24/Actor_05/03-01-02-01-02-02-05.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 2357/2880 [39:21<07:08,  1.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 67807] to have 1 channels, but got 2 channels instead\n","Skipping file ./kaggle/Actor_05/03-01-02-01-02-02-05.wav due to 'NoneType' object has no attribute 'size'\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2880/2880 [46:57<00:00,  1.02it/s]\n"]}],"source":["from tqdm import tqdm\n","\n","all_scores_n = []\n","all_scores_s = []\n","all_scores_m = []\n","all_scores_l = []\n","all_saved_files = []\n","\n","for input_file in tqdm(all_input_files):\n","    try:\n","        # Load audio\n","        audio, sample_rate = load_audio_file(input_file)\n","\n","        # Generate watermarked audio\n","        watermarked_audio = generate_watermark_audio(audio, sample_rate)\n","\n","        # Perform SHUSH attacks\n","        shush_attack_audio_n = af.shush(watermarked_audio, fraction=0.001)\n","        shush_attack_audio_s = af.shush(watermarked_audio, fraction=0.01)\n","        shush_attack_audio_m = af.shush(watermarked_audio, fraction=0.1)\n","        shush_attack_audio_l = af.shush(watermarked_audio, fraction=0.3)\n","\n","        # Compute scores\n","        shush_score_n = detect_watermark_audio(shush_attack_audio_n, sample_rate)\n","        shush_score_s = detect_watermark_audio(shush_attack_audio_s, sample_rate)\n","        shush_score_m = detect_watermark_audio(shush_attack_audio_m, sample_rate)\n","        shush_score_l = detect_watermark_audio(shush_attack_audio_l, sample_rate)\n","\n","        # Store scores\n","        all_scores_n.append(float(shush_score_n))\n","        all_scores_s.append(float(shush_score_s))\n","        all_scores_m.append(float(shush_score_m))\n","        all_scores_l.append(float(shush_score_l))\n","        all_saved_files.append(input_file)\n","    except Exception as e:\n","        print(f\"Skipping file {input_file} due to {e}\")\n","        pass"]},{"cell_type":"markdown","metadata":{},"source":["## Store results and calculate metrics"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:59:10.242250Z","iopub.status.busy":"2024-03-15T06:59:10.241976Z","iopub.status.idle":"2024-03-15T06:59:10.249995Z","shell.execute_reply":"2024-03-15T06:59:10.248957Z","shell.execute_reply.started":"2024-03-15T06:59:10.242224Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame({\n","    \"input_file\" : all_saved_files,\n","    \"watermark_confidence_n\" : all_scores_n,\n","    \"watermark_confidence_s\" : all_scores_s,\n","    \"watermark_confidence_m\" : all_scores_m,\n","    \"watermark_confidence_l\" : all_scores_l,\n","})"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:59:10.251570Z","iopub.status.busy":"2024-03-15T06:59:10.251203Z","iopub.status.idle":"2024-03-15T06:59:10.278172Z","shell.execute_reply":"2024-03-15T06:59:10.277277Z","shell.execute_reply.started":"2024-03-15T06:59:10.251528Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>watermark_confidence_n</th>\n","      <th>watermark_confidence_s</th>\n","      <th>watermark_confidence_m</th>\n","      <th>watermark_confidence_l</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.998851</td>\n","      <td>0.990335</td>\n","      <td>0.900382</td>\n","      <td>0.699686</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.000114</td>\n","      <td>0.000347</td>\n","      <td>0.000789</td>\n","      <td>0.000478</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.996135</td>\n","      <td>0.986962</td>\n","      <td>0.876117</td>\n","      <td>0.695407</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.998792</td>\n","      <td>0.990220</td>\n","      <td>0.900214</td>\n","      <td>0.699631</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.998841</td>\n","      <td>0.990385</td>\n","      <td>0.900339</td>\n","      <td>0.699782</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.998895</td>\n","      <td>0.990570</td>\n","      <td>0.900625</td>\n","      <td>0.699918</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.999432</td>\n","      <td>0.990909</td>\n","      <td>0.901558</td>\n","      <td>0.700586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       watermark_confidence_n  watermark_confidence_s  watermark_confidence_m  \\\n","count             2870.000000             2870.000000             2870.000000   \n","mean                 0.998851                0.990335                0.900382   \n","std                  0.000114                0.000347                0.000789   \n","min                  0.996135                0.986962                0.876117   \n","25%                  0.998792                0.990220                0.900214   \n","50%                  0.998841                0.990385                0.900339   \n","75%                  0.998895                0.990570                0.900625   \n","max                  0.999432                0.990909                0.901558   \n","\n","       watermark_confidence_l  \n","count             2870.000000  \n","mean                 0.699686  \n","std                  0.000478  \n","min                  0.695407  \n","25%                  0.699631  \n","50%                  0.699782  \n","75%                  0.699918  \n","max                  0.700586  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["df.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## We note that Audioseal performs very well in recalling the watermarks - even in extreme conditions of masking the first 30\\% of the audio, the average confidence is $0.699678$. "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":107620,"sourceId":256618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"evn","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
