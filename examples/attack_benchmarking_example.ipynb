{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Benchmarking Audioseal on the SHUSH attack applied on RAVDESS Dataset\n","\n","In this notebook, we outline the steps taken to benchmark the Audioseal architecture against different attacks on a dataset of audio files.  \n","In particular, we follow these steps:\n","- Load audio files from a dataset \n","- Watermark each audio file using Audioseal\n","- Perform perturbations/attacks to the audio files\n","- Detect the watermarks on these attacked files and keep track of the confidence of Audioseal in its predictions that the files are watermarked.\n","\n","\n","For a better understanding of Audioseal and its functionalities, it is highly recommended to go through the [Getting started notebook](https://github.com/facebookresearch/audioseal/blob/main/examples/Getting_started.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset\n","\n","We use the [RAVDESS Emotional Speech audio](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) dataset for this experiment.   \n","When added to a Kaggle notebook environment, all input datasets are stored in the read-only `/kaggle/input` path. If you are not using Kaggle, or have stored your files elsewhere, you can load nested audio files by modifying `PARENT_FILES_DIR` in the cell below."]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-15T06:51:03.909949Z","iopub.status.busy":"2024-03-15T06:51:03.909220Z","iopub.status.idle":"2024-03-15T06:51:04.354260Z","shell.execute_reply":"2024-03-15T06:51:04.353256Z","shell.execute_reply.started":"2024-03-15T06:51:03.909904Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of input files: 2880\n"]}],"source":["import numpy as np \n","import pandas as pd\n","import os\n","\n","all_input_files = []\n","PARENT_FILES_DIR = '/kaggle/input'\n","\n","for dirname, _, filenames in os.walk(PARENT_FILES_DIR):\n","    for filename in filenames:\n","        if \"wav\" in filename:\n","            all_input_files.append(os.path.join(dirname, filename))\n","            \n","print(f\"Number of input files: {len(all_input_files)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Installations and Imports "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:05.910354Z","iopub.status.busy":"2024-03-15T06:51:05.909237Z","iopub.status.idle":"2024-03-15T06:51:20.351281Z","shell.execute_reply":"2024-03-15T06:51:20.350239Z","shell.execute_reply.started":"2024-03-15T06:51:05.910319Z"},"trusted":true},"outputs":[],"source":["import sys\n","!{sys.executable} -m pip install -q torchaudio soundfile matplotlib audioseal\n","\n","import typing as tp\n","import julius\n","import torch\n","import torchaudio\n","import urllib"]},{"cell_type":"markdown","metadata":{},"source":["### Load Audioseal models"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.354221Z","iopub.status.busy":"2024-03-15T06:51:20.353436Z","iopub.status.idle":"2024-03-15T06:51:20.378701Z","shell.execute_reply":"2024-03-15T06:51:20.377805Z","shell.execute_reply.started":"2024-03-15T06:51:20.354185Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.380975Z","iopub.status.busy":"2024-03-15T06:51:20.379901Z","iopub.status.idle":"2024-03-15T06:51:20.919397Z","shell.execute_reply":"2024-03-15T06:51:20.918564Z","shell.execute_reply.started":"2024-03-15T06:51:20.380948Z"},"trusted":true},"outputs":[],"source":["from audioseal import AudioSeal\n","\n","model = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n","detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")"]},{"cell_type":"markdown","metadata":{},"source":["### Helper functions to load audio data, watermark audio, and get prediction scores for audio"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:20.922026Z","iopub.status.busy":"2024-03-15T06:51:20.921593Z","iopub.status.idle":"2024-03-15T06:51:21.091167Z","shell.execute_reply":"2024-03-15T06:51:21.090157Z","shell.execute_reply.started":"2024-03-15T06:51:20.921992Z"},"trusted":true},"outputs":[],"source":["model = model.to(device)\n","detector = detector.to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:21.092660Z","iopub.status.busy":"2024-03-15T06:51:21.092352Z","iopub.status.idle":"2024-03-15T06:51:21.105098Z","shell.execute_reply":"2024-03-15T06:51:21.104097Z","shell.execute_reply.started":"2024-03-15T06:51:21.092635Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Secret message: tensor([[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1]], device='cuda:0',\n","       dtype=torch.int32)\n"]}],"source":["secret_message = torch.randint(0, 2, (1, 16), dtype=torch.int32)\n","secret_message = secret_message.to(device)\n","print(f\"Secret message: {secret_message}\")\n","\n","# Function to load an audio file from its file path\n","def load_audio_file(\n","    file_path: str\n",") -> tp.Optional[tp.Tuple[torch.Tensor, int]]:\n","    try:\n","        wav, sample_rate = torchaudio.load(file_path)\n","        return wav, sample_rate\n","    except Exception as e:\n","        print(f\"Error while loading audio: {e}\")\n","        return None\n","    \n","# Function to generate a watermark for the audio and embed it into a new audio tensor\n","def generate_watermark_audio(\n","    tensor: torch.Tensor,\n","    sample_rate: int\n",") -> tp.Optional[torch.Tensor]:\n","    try:\n","        global model, device, secret_message\n","        audios = tensor.unsqueeze(0).to(device)\n","        watermarked_audio = model(audios, sample_rate=sample_rate, message=secret_message.to(device), alpha=1)\n","        return watermarked_audio\n","\n","    \n","    except Exception as e:\n","        print(f\"Error while watermarking audio: {e}\")\n","        return None\n","    \n","# Function to get the confidence score that an audio tensor was watermarked by Audioseal\n","def detect_watermark_audio(\n","    tensor: torch.Tensor,\n","    sample_rate: int,\n","    message_threshold: float = 0.50\n",") -> tp.Optional[float]:\n","    try:\n","        global detector, device\n","        # In our analysis we are not concerned with the hidden/embedded message as of now\n","        result, _ = detector.detect_watermark(tensor, sample_rate=sample_rate, message_threshold=message_threshold)\n","        return float(result)\n","    except Exception as e:\n","        print(f\"Error while detecting watermark: {e}\")\n","        return None"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Audio attacks\n","\n","- In this notebook, we use the `SHUSH` attack.\n","- For more attacks and their descriptions, please refer to the [source](https://github.com/facebookresearch/audioseal/blob/main/examples/attacks.py)."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:33.919489Z","iopub.status.busy":"2024-03-15T06:51:33.919084Z","iopub.status.idle":"2024-03-15T06:51:33.962401Z","shell.execute_reply":"2024-03-15T06:51:33.961261Z","shell.execute_reply.started":"2024-03-15T06:51:33.919460Z"},"trusted":true},"outputs":[],"source":["from attacks import AudioEffects as af"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Experimental setup\n","- `fraction` values: \\{0.1\\%, 1\\%, 10\\%, 30\\%\\}\n","- `nomenclature` : n, s, m, l\n","\n","In this notebook, we set the above parameters for the SHUSH attack and note the average confidence scores of Audioseal in predicting the presence of watermarks for these attacked audio files."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:39.665411Z","iopub.status.busy":"2024-03-15T06:51:39.665025Z","iopub.status.idle":"2024-03-15T06:51:39.673355Z","shell.execute_reply":"2024-03-15T06:51:39.672473Z","shell.execute_reply.started":"2024-03-15T06:51:39.665382Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x791cf49c2890>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import random\n","random.seed(42)\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(42)\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:51:40.533674Z","iopub.status.busy":"2024-03-15T06:51:40.532744Z","iopub.status.idle":"2024-03-15T06:59:10.240026Z","shell.execute_reply":"2024-03-15T06:59:10.239069Z","shell.execute_reply.started":"2024-03-15T06:51:40.533640Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  5%|▌         | 148/2880 [01:38<09:22,  4.86it/s]  "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 67807] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/Actor_05/03-01-02-01-02-02-05.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 335/2880 [02:27<04:57,  8.56it/s]  "]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 57663] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-02-01-01-02-01.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 339/2880 [02:27<04:13, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 52324] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-08-01-02-02-01.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 425/2880 [02:45<03:49, 10.68it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 69942] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/Actor_20/03-01-06-01-01-02-20.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 431/2880 [02:45<03:42, 11.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 55528] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/Actor_20/03-01-03-01-02-01-20.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▍     | 1289/2880 [04:43<02:16, 11.62it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 67807] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_05/03-01-02-01-02-02-05.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████▏    | 1476/2880 [05:02<02:07, 11.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 57663] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-02-01-01-02-01.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████▏    | 1478/2880 [05:02<01:55, 12.10it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 52324] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-08-01-02-02-01.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 54%|█████▍    | 1564/2880 [05:10<01:57, 11.20it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 69942] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_20/03-01-06-01-01-02-20.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▍    | 1570/2880 [05:11<01:52, 11.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Error while watermarking audio: Given groups=1, weight of size [32, 1, 7], expected input[1, 2, 55528] to have 1 channels, but got 2 channels instead\n","Skipping file /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_20/03-01-03-01-02-01-20.wav due to 'NoneType' object has no attribute 'shape'\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2880/2880 [07:29<00:00,  6.40it/s]\n"]}],"source":["from tqdm import tqdm\n","\n","all_scores_n = []\n","all_scores_s = []\n","all_scores_m = []\n","all_scores_l = []\n","all_saved_files = []\n","\n","for input_file in tqdm(all_input_files):\n","    try:\n","        # Load audio\n","        audio, sample_rate = load_audio_file(input_file)\n","\n","        # Generate watermarked audio\n","        watermarked_audio = generate_watermark_audio(audio, sample_rate)\n","\n","        # Perform SHUSH attacks\n","        shush_attack_audio_n = af.shush(watermarked_audio, fraction=0.001)\n","        shush_attack_audio_s = af.shush(watermarked_audio, fraction=0.01)\n","        shush_attack_audio_m = af.shush(watermarked_audio, fraction=0.1)\n","        shush_attack_audio_l = af.shush(watermarked_audio, fraction=0.3)\n","\n","        # Compute scores\n","        shush_score_n = detect_watermark_audio(shush_attack_audio_n, sample_rate)\n","        shush_score_s = detect_watermark_audio(shush_attack_audio_s, sample_rate)\n","        shush_score_m = detect_watermark_audio(shush_attack_audio_m, sample_rate)\n","        shush_score_l = detect_watermark_audio(shush_attack_audio_l, sample_rate)\n","\n","        # Store scores\n","        all_scores_n.append(float(shush_score_n))\n","        all_scores_s.append(float(shush_score_s))\n","        all_scores_m.append(float(shush_score_m))\n","        all_scores_l.append(float(shush_score_l))\n","        all_saved_files.append(input_file)\n","    except Exception as e:\n","        print(f\"Skipping file {input_file} due to {e}\")\n","        pass"]},{"cell_type":"markdown","metadata":{},"source":["## Store results and calculate metrics"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:59:10.242250Z","iopub.status.busy":"2024-03-15T06:59:10.241976Z","iopub.status.idle":"2024-03-15T06:59:10.249995Z","shell.execute_reply":"2024-03-15T06:59:10.248957Z","shell.execute_reply.started":"2024-03-15T06:59:10.242224Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame({\n","    \"input_file\" : all_saved_files,\n","    \"watermark_confidence_n\" : all_scores_n,\n","    \"watermark_confidence_s\" : all_scores_s,\n","    \"watermark_confidence_m\" : all_scores_m,\n","    \"watermark_confidence_l\" : all_scores_l,\n","})"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T06:59:10.251570Z","iopub.status.busy":"2024-03-15T06:59:10.251203Z","iopub.status.idle":"2024-03-15T06:59:10.278172Z","shell.execute_reply":"2024-03-15T06:59:10.277277Z","shell.execute_reply.started":"2024-03-15T06:59:10.251528Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>watermark_confidence_n</th>\n","      <th>watermark_confidence_s</th>\n","      <th>watermark_confidence_m</th>\n","      <th>watermark_confidence_l</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","      <td>2870.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.998849</td>\n","      <td>0.990138</td>\n","      <td>0.900209</td>\n","      <td>0.699678</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.000776</td>\n","      <td>0.000738</td>\n","      <td>0.000763</td>\n","      <td>0.000516</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.976302</td>\n","      <td>0.967376</td>\n","      <td>0.876146</td>\n","      <td>0.694676</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.998877</td>\n","      <td>0.990022</td>\n","      <td>0.900083</td>\n","      <td>0.699631</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.998922</td>\n","      <td>0.990202</td>\n","      <td>0.900260</td>\n","      <td>0.699777</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.998963</td>\n","      <td>0.990334</td>\n","      <td>0.900352</td>\n","      <td>0.699923</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.999177</td>\n","      <td>0.990550</td>\n","      <td>0.900958</td>\n","      <td>0.700464</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       watermark_confidence_n  watermark_confidence_s  watermark_confidence_m  \\\n","count             2870.000000             2870.000000             2870.000000   \n","mean                 0.998849                0.990138                0.900209   \n","std                  0.000776                0.000738                0.000763   \n","min                  0.976302                0.967376                0.876146   \n","25%                  0.998877                0.990022                0.900083   \n","50%                  0.998922                0.990202                0.900260   \n","75%                  0.998963                0.990334                0.900352   \n","max                  0.999177                0.990550                0.900958   \n","\n","       watermark_confidence_l  \n","count             2870.000000  \n","mean                 0.699678  \n","std                  0.000516  \n","min                  0.694676  \n","25%                  0.699631  \n","50%                  0.699777  \n","75%                  0.699923  \n","max                  0.700464  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## We note that Audioseal performs very well in recalling the watermarks - even in extreme conditions of masking the first 30\\% of the audio, the average confidence is $0.699678$. "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":107620,"sourceId":256618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
